diff --git a/tensorflow/core/BUILD b/tensorflow/core/BUILD
index 9bcd87aede..53cedf7be3 100644
--- a/tensorflow/core/BUILD
+++ b/tensorflow/core/BUILD
@@ -2426,6 +2426,13 @@ LIB_INTERNAL_DEFINES = (
     tf_additional_numa_lib_defines()
 )

+#cc_import(
+#    name = "mtmc_profiler",
+    # hdrs = ["env.h", "guard_sampler.h", "mtmc_profiler.h", "perfmon_collector.h", "perfmon_config.h", "util.h"],
+    # shared_library = "libpfc.so",
+#    static_library = "libpfca.a",
+#)
+
 cc_library(
     name = "lib_internal",
     srcs = LIB_INTERNAL_PRIVATE_HEADERS,
@@ -2477,6 +2484,7 @@ cc_library(
     copts = tf_copts(),
     defines = LIB_INTERNAL_DEFINES,
     deps = tf_additional_lib_deps() + [
+               "//mtmc_profiler:mtmc_profiler",
                ":core_stringpiece",
                ":lib_hash_crc32c_accelerate_internal",
                ":lib_proto_parsing",
diff --git a/tensorflow/core/common_runtime/executor.cc b/tensorflow/core/common_runtime/executor.cc
index da2954a1c6..ffefd259b6 100644
--- a/tensorflow/core/common_runtime/executor.cc
+++ b/tensorflow/core/common_runtime/executor.cc
@@ -72,6 +72,15 @@ limitations under the License.
 #include "tensorflow/core/profiler/lib/traceme.h"
 #include "tensorflow/core/util/tensor_slice_reader_cache.h"

+#define MTMC_PROFILER
+
+#ifdef MTMC_PROFILER
+
+#include "mtmc/mtmc_temp_profiler.h"
+#include "mtmc/util.h"
+
+#endif
+
 namespace tensorflow {
 namespace {

@@ -1713,6 +1722,26 @@ void ExecutorState::Process(TaggedNode tagged_node, int64 scheduled_nsec) {
       nodestats::SetAllStart(stats);
     }

+#ifdef MTMC_PROFILER
+
+    mtmc::MTMCTemprolProfiler& prof = mtmc::MTMCTemprolProfiler::getInstance();
+
+    size_t hash_id_int = mtmc::util::GenHashId();
+    auto hash_id = std::to_string(hash_id_int);
+
+    mtmc::Context mtmc_ctx;
+    mtmc_ctx.is_default = false;
+    mtmc_ctx.name = strings::StrCat("~",node->def().name(),"~",node->def().op(),"~",hash_id,"~","~",std::to_string(params.step_id));
+    mtmc_ctx.ctx_hash_id = hash_id_int;
+
+    prof.UpdateCurrentCtx(mtmc_ctx);
+
+    // MTMC InterOp Start
+    prof.LogStart({0,0,0,1}, strings::StrCat("INTEROP~",node->def().name(),"~",node->def().op(),"~","1",
+                                             "~",absl::StrJoin(node->requested_inputs(), "|"),"~",std::to_string(params.step_id)), hash_id_int);
+
+#endif
+
     if (vlog_) {
       VLOG(1) << "Process node: " << id << " step " << params.step_id << " "
               << SummarizeNode(*node) << (tagged_node.is_dead ? " is dead" : "")
@@ -2212,6 +2241,15 @@ bool ExecutorState::NodeDone(const Status& s, const Node* node,
                              const TaggedNodeSeq& ready,
                              NodeExecStatsInterface* stats,
                              TaggedNodeReadyQueue* inline_ready) {
+
+#ifdef MTMC_PROFILER
+
+  mtmc::MTMCTemprolProfiler& prof = mtmc::MTMCTemprolProfiler::getInstance();
+  prof.GetCurrentCtx()->is_default = true;
+  prof.LogEnd();
+
+#endif
+
   nodestats::SetAllEnd(stats);
   if (stats) {
     if (stats_collector_) {
diff --git a/tensorflow/core/util/mkl_threadpool.h b/tensorflow/core/util/mkl_threadpool.h
index 70436dbd41..9f4a6c338d 100644
--- a/tensorflow/core/util/mkl_threadpool.h
+++ b/tensorflow/core/util/mkl_threadpool.h
@@ -69,7 +69,7 @@ struct MklDnnThreadPool : public threadpool_iface {
                              ->workers->AsEigenThreadPool()) {}
   virtual int get_num_threads() const override {
     //return eigen_interface_->NumThreads();
-    int ret = eigen_interface_->NumThreads() > 14 ? 14 : eigen_interface_->NumThreads();
+    int ret = eigen_interface_->NumThreads() > 24 ? 24 : eigen_interface_->NumThreads();
     return ret;
   }
   virtual bool get_in_parallel() const override {
diff --git a/tensorflow/python/tools/api/generator/create_python_api.py b/tensorflow/python/tools/api/generator/create_python_api.py
index 98cd159a63..6aca51ac1e 100644
--- a/tensorflow/python/tools/api/generator/create_python_api.py
+++ b/tensorflow/python/tools/api/generator/create_python_api.py
@@ -31,6 +31,8 @@ from tensorflow.python.util import tf_export
 API_ATTRS = tf_export.API_ATTRS
 API_ATTRS_V1 = tf_export.API_ATTRS_V1

+os.environ["MTMC_PROF_DISABLE"]="1"
+
 _LAZY_LOADING = False
 _API_VERSIONS = [1, 2]
 _COMPAT_MODULE_TEMPLATE = 'compat.v%d'
